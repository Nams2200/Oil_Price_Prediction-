{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import plotly.express as pl\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"oil.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre - processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape of the Data\n",
    "df.shape\n",
    "# In out dataset we 5000 rows and 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Datatypes of the Data\n",
    "df.info()\n",
    "# In our dataset we have Three Datacolumns contain homogenous type of Data\n",
    "# We will Convert them to there Proper Format\n",
    "# So it will Help to perform EDA for mnore Insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Date columns to datetime Datatype\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Volume column to Integer Datatype and multiplying with 1000 when there is K and by 1000000 when there is M\n",
    "\n",
    "df['Volume'] = df['Volume'].replace({'K':'*1e3','M':'*1e6'},regex=True).map(pd.eval).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing % with ' ' from Che% column and converting it into float datatype\n",
    "\n",
    "df['Che%'] = df['Che%'].replace({'%':' '},regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chenking the datatypes of again\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Some Discreptive Statictical parameters\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null Values in the Data\n",
    "\n",
    "df.isnull().sum()\n",
    "sns.heatmap(df.isnull(),cmap='viridis')\n",
    "\n",
    "# Looking to the Heatmap we can undersatnd that there is no Null Value Present in the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Outlier\n",
    "# So will Check the Outlier in Price Column beacaue it Target Variable and While Predecting Future Price of the Oil\n",
    "# Wihtout Knowing Price of the Oil we cannot estimate the Low,High,Open and Volume of the data\n",
    "\n",
    "plt.title('Outlier Detection in Price Column')\n",
    "sns.boxplot(df['Price'],color='purple')\n",
    "\n",
    "# Looking at the Boxplot of Price columns we can see there are few outlier above the upper limit of the price column\n",
    "# Show we will exclude the Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Upper Limit of the Price Column\n",
    "\n",
    "upper_limit = (np.quantile(df['Price'],0.75) + 1.5*(np.quantile(df['Price'],0.75) - np.quantile(df['Price'],0.25)))\n",
    "upper_limit\n",
    "\n",
    "# Filtering the price Column with its Upper Limit by using condition 'price <= 142.83249999999998'\n",
    "\n",
    "df = df[df['Price'] <= 142.83249999999998 ]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking the Distribution Each Column Using histogram \n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(3,2,1)\n",
    "sns.histplot(df['High'],bins=30,color='skyblue')\n",
    "plt.title('distribtuion of High Prices')\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "sns.histplot(df['Open'],bins=30,color='salmon')\n",
    "plt.title('distribtuion of Open Prices')\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "sns.histplot(df['Low'],bins=30,color='green')\n",
    "plt.title(\"Distribution of Low Prices\")\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "sns.histplot(df['Volume'],bins=30,color='purple')\n",
    "plt.title(\"Distribution of Trading Volume\")\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "sns.histplot(df['Price'],bins=30,color='orange')\n",
    "plt.title(\"Distribution of Price\")\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "sns.histplot(df['Price'],bins=30,color='yellow')\n",
    "plt.title(\"Distribution of Che%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize of Price column According to Time Series\n",
    "# From the Graph we understand In The month july 2008 Oil Price was maximum 145.18 and In month of January 2002 Oil price was Minimum 17.97\n",
    "# In 2008 there Was Sudden Change in Oil price from 145.18 to 33.87 due to some crises\n",
    "plt.figure(figsize=(14,4))\n",
    "fig = pl.line(data_frame=df,x = df['Date'],y = df['Price'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot of Price with Selected columns\n",
    "\n",
    "sns.pairplot(data=df[['Price','Open','High','Low','Volume']],palette='mist')\n",
    "plt.title('pairplot of Price and Other Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Correlation \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(),annot=True,cmap='coolwarm',linewidths=0.5,vmin=-1,vmax=1,fmt='0.2f')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chenking How Volume get change as the difference Between Open Price and High price get Increase\n",
    "\n",
    "df['open - high'] = df['Open'] - df['High']\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.barplot(data=df,x = df['open - high'],y = df['Volume'])\n",
    "\n",
    "# Looking at the Graph We can undestand as the Difference between Open and High Price increase  the Volume silghtly get changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chenking How Volume get change as the difference Between High Price and Low price get Increase or Decrease\n",
    "\n",
    "df['High - Low'] = df['High'] - df['Low']\n",
    "plt.figure(figsize=(20,6))\n",
    "sns.barplot(data=df,x = df['High - Low'],y = df['Volume'])\n",
    "\n",
    "# Looking at the Graph We can undestand as the Difference between High and Low Price increase the Volume also get Increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Feature Engineering On Date column to Extract Year,Month.\n",
    "\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Bar Plot of Year wise Price of the Oil\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.barplot(data=df ,x =df['Year'],y = df['Price'])\n",
    "plt.title(\"Barplot of Oil Prices by Year\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of Yearly Price\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=df ,x =df['Year'],y = df['Price'])\n",
    "plt.title(\"Boxplot of Oil Prices by Year\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "\n",
    "# Looking at the boxplot graph between Year and price\n",
    "# In year 2008 Oil price achived maximum price above 140 barrel and there was maximum price changes in oil from 35 to 140 barrel\n",
    "# In year 2001 Oil Achived Minimum price approximatley 18 per barrel\n",
    "# In year 2003 there was Minimum Changes in the Oil Price \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price of Oil Monthly wise in Each Year\n",
    "fig = pl.bar(df,x = df['Month'], y = df['Price'],color=df['Year'])\n",
    "fig.update_layout(title = \"Monthly Price of Oil in Each Year\",\n",
    "                  xaxis_title = 'Month',\n",
    "                  yaxis_title = \"Price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Average of Oil Price\n",
    "\n",
    "montly_average_price = df.groupby('Month')['Price'].mean()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x = montly_average_price.index,y = montly_average_price.values,palette='viridis')\n",
    "plt.title('Monthly average Price of Oil')\n",
    "plt.xlabel('Month')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylabel('year')\n",
    "plt.show()\n",
    "\n",
    "# Looking at the graph we can understand May Month have maximum average Price above 65 and December Month have Minimum Average price as 58\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Mean of Oil prices over Specific Window\n",
    "\n",
    "rolling_window = 30\n",
    "rolling_mean = df['Price'].rolling(window=rolling_window).mean()\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(df.index,df['Price'],label=\"Oil Price\",color = 'blue',alpha = 0.7)\n",
    "plt.plot(rolling_mean.index,rolling_mean,label = f'Rolling Window ({rolling_window} days)',color = 'red')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Seasonal_Decompose Plot on Price Column\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Decompose the time series into components\n",
    "# Assuming Seasonality for time series of 12 months\n",
    "result = seasonal_decompose(df['Price'],model='additive',period=12)\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(df['Price'],label = 'Original Time Series')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Original Components')\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(result.trend,label = 'Trends')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Trend Components')\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(result.seasonal,label = 'Seasonality')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Seasonal Components')\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(result.resid,label = 'residual or Noise')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Residual Components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Seasonal_Decompose Plot on Price Column\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Decompose the time series into components\n",
    "# Assuming Seasonality for time series of 12 months\n",
    "result = seasonal_decompose(df['Price'],model='multiplicative',period=12)\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(df['Price'],label = 'Original Time Series')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Original Components')\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(result.trend,label = 'Trends')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Trend Components')\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(result.seasonal,label = 'Seasonality')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Seasonal Components')\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(result.resid,label = 'residual or Noise')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Residual Components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Feature Engineering On Price Column\n",
    "df['Daily_Price_Change'] = df['Price'].diff()\n",
    "\n",
    "# Feature Engineering: Rolling Mean\n",
    "window_size = 7  # Adjust window size as needed\n",
    "df['Rolling_Mean'] = df['Price'].rolling(window=window_size).mean()\n",
    "\n",
    "# Feature Engineering: Seasonal Decomposition (Trend Component)\n",
    "result = seasonal_decompose(df['Price'], model='additive', period=30)  # Adjust period as needed\n",
    "df['Trend_Component'] = result.trend\n",
    "\n",
    "# Display the first few rows of the dataframe after feature engineering\n",
    "print(df.head())\n",
    "\n",
    "# Visualize the new features\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Price'], label='Oil Prices')\n",
    "plt.plot(df['Daily_Price_Change'], label='Daily Price Change', linestyle='--')\n",
    "plt.plot(df['Rolling_Mean'], label=f'Rolling Mean ({window_size} days)', linestyle='-.')\n",
    "plt.plot(df['Trend_Component'], label='Trend Component (Seasonal Decomposition)', linestyle=':')\n",
    "plt.title('Oil Price and Engineered Features')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Further Step to Perform Tests like Dickey-Fuller test and KPSS test to check the stationarity of the data\n",
    "\n",
    "df1 = df.iloc[:,[0,1,9,10]]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Price']\n",
    "plt.figure(figsize=(8,4))\n",
    "y.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the grpah we ca see data is not in constant form\n",
    "The trend is increasing year by year and get decrease at some interval\n",
    "To make in statnary form we will perform Dickey_fuller_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the library\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will use transformations to normalise \n",
    "y1 = y-y.shift(1)\n",
    "y1 = y1[1:]  # ignoring 1st value as it is null value\n",
    "y2 = np.log(y1-np.min(y1)+1)  # using log to ignore negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2\n",
    "# Looking at the Data we can see that Data is not in Stationary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'test_statistic: {result[0]}')\n",
    "print(f'p:value: {result[1]}')\n",
    "print(f'critical value: {result[4]}')\n",
    "\n",
    "if result[1] > 0.05:\n",
    "    print('series is not stationary')\n",
    "else:\n",
    "    print('series is stationary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPSS Test\n",
    "\n",
    "The Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test is another test to check for stationarity in a time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats , p , lags , critical_value = kpss(df['Price'] , 'ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Statistic: {stats}')\n",
    "print(f'p-value: {p}')\n",
    "print(f'critical value: {critical_value}')\n",
    "\n",
    "if p < 0.05 :\n",
    "    print('Series is not Stationary')\n",
    "else:\n",
    "    print('Series is Stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using D parameter of ARIMA Model to check make data stationary\n",
    "import pmdarima as pm\n",
    "pm.arima.ndiffs(df['Price'] , alpha=0.05 , test='kpss' , max_d=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_g = df['Price'].rolling(window=2).apply(lambda x : x.iloc[1] - x.iloc[0]).dropna()\n",
    "lag_g.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.arima.ndiffs(lag_g , alpha=0.05 , test='kpss' , max_d=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(lag_g)\n",
    "\n",
    "print(f'test_statistic: {result[0]}')\n",
    "print(f'p:value: {result[1]}')\n",
    "print(f'critical value: {result[4]}')\n",
    "\n",
    "if result[1] > 0.05:\n",
    "    print('series is not stationary')\n",
    "else:\n",
    "    print('series is stationary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Rollling Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "train_data = df[:train_size]\n",
    "test_data = df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rolling_average(data,window_size):\n",
    "    return data['Price'].rolling(window=window_size).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 7  # Adjust the window size as needed\n",
    "train_data['SRA'] = simple_rolling_average(train_data, window)\n",
    "test_data['SRA'] = simple_rolling_average(test_data, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Remove NaN values from test_data\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "sma_mae = mean_absolute_error(test_data['Price'], test_data['SRA'])\n",
    "sma_mse = mean_squared_error(test_data['Price'], test_data['SRA'])\n",
    "sma_rmse = np.sqrt(sma_mse)\n",
    "\n",
    "print(\"SRA Model Evaluation:\")\n",
    "print(\"MAE:\", sma_mae)\n",
    "print(\"MSE:\", sma_mse)\n",
    "print(\"RMSE:\", sma_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_data.index, test_data['Price'], label='Actual Prices')\n",
    "plt.plot(test_data.index, test_data['SRA'], label='Random Forest Forecast', linestyle='dashed')\n",
    "plt.title('Time Series Forecasting with Different Models')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set for Random Forest model\n",
    "\n",
    "df_rf = df.iloc[:,[0,1,5]]\n",
    "df_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf['Year'] = df_rf['Date'].dt.year\n",
    "df_rf['Month'] = df_rf['Date'].dt.month\n",
    "df_rf['Day'] = df_rf['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Year', 'Month', 'Day', 'Volume']  # Features used for prediction\n",
    "X = df_rf[features]\n",
    "y = df_rf['Price']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Random Forest model training\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust the number of estimators based on your dataset size\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "predictions = model_rf.predict(X_test)\n",
    "rf_mae = mean_absolute_error(y_test, predictions)\n",
    "rf_mse = mean_squared_error(y_test,predictions)\n",
    "print(\"Mean Absolute Error:\", rf_mae)\n",
    "print(\"mean_squared_error\",rf_mse)\n",
    "print(\"root mean squared Error\",np.sqrt(rf_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "\n",
    "joblib.dump(model_rf, 'random_forest_model_save.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) XGB Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb = df.iloc[:,[0,1,5]]\n",
    "df_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb['Year'] = df_xgb['Date'].dt.year\n",
    "df_xgb['Month'] = df_xgb['Date'].dt.month\n",
    "df_xgb['Day'] = df_xgb['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "features = ['Year', 'Month', 'Day', 'Volume']  # Features used for prediction\n",
    "X = df_xgb[features]\n",
    "y = df_xgb['Price']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model training\n",
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(n_estimators=1000, learning_rate=0.05)  # You can adjust the hyperparameters based on your dataset\n",
    "model.fit(X_train, y_train, \n",
    "          early_stopping_rounds=5, \n",
    "          eval_set=[(X_test, y_test)], \n",
    "          verbose=False)\n",
    "\n",
    "# Model Evaluation\n",
    "predictions_xg = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, predictions_xg)\n",
    "mse = mean_squared_error(y_test,predictions_xg)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"mean_squared_error\",mse)\n",
    "print(\"Root Mean Squared Error\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Auto Regerssor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR Model\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "ar_model = AutoReg(train_data['Price'], lags=31)  # Adjust 'lags' based on your data\n",
    "ar_fit = ar_model.fit()\n",
    "ar_pred = ar_fit.predict(start=len(train_data), end=len(train_data) + len(test_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.dropna()\n",
    "ar_mae = mean_absolute_error(test_data['Price'],ar_pred)\n",
    "ar_mse = mean_squared_error(test_data['Price'], ar_pred)\n",
    "ar_rmse = np.sqrt(ar_mse)\n",
    "\n",
    "print(\"AR Model Evaluation:\")\n",
    "print(\"MAE:\", ar_mae)\n",
    "print(\"MSE:\", ar_mse)\n",
    "print(\"RMSE:\", ar_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_data.index, test_data['Price'], label='Actual Prices')\n",
    "plt.plot(test_data.index, ar_pred, label='Random Forest Forecast', linestyle='dashed')\n",
    "plt.title('Time Series Forecasting with Different Models')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(train_data[['Price']])\n",
    "scaled_test = scaler.transform(test_data[['Price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='rbf')  # Adjust the kernel as needed\n",
    "model.fit(scaled_train, train_data['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_mae = mean_absolute_error(test_data['Price'], predictions)\n",
    "svr_mse = mean_squared_error(test_data['Price'], predictions)\n",
    "svr_rmse = np.sqrt(svr_mse)\n",
    "\n",
    "print(\"SVR Model Evaluation:\")\n",
    "print(\"MAE:\", svr_mae)\n",
    "print(\"MSE:\", svr_mse)\n",
    "print(\"RMSE:\", svr_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.iloc[:,[0,1]]\n",
    "df_final.dropna()\n",
    "df_final.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geting Best order for ARIMA model\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "stepwise_fit = auto_arima(df_final['Price'],trace=True,suppress_warnings=True)\n",
    "stepwise_fit.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "train_size = int(len(df_final) * 0.8)\n",
    "train, test = df_final[:train_size], df_final[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "arima_model = ARIMA(train, order=(5,1,0))  # Adjust 'order' based on your data\n",
    "arima_fit = arima_model.fit()\n",
    "arima_pred = arima_fit.predict(start=len(train), end=len(train) + len(test) - 1, typ='levels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_values, predicted_values):\n",
    "    mae = mean_absolute_error(true_values, predicted_values)\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "    return mae, rmse\n",
    "arima_mae, arima_rmse = evaluate_model(test['Price'], arima_pred)\n",
    "print(arima_mae)\n",
    "print(arima_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test.index, test['Price'], label='Actual Prices')\n",
    "plt.plot(test.index, arima_pred, label='ARIMA Predictions')\n",
    "plt.title('Oil Price Prediction Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_size = int(len(df_final) * 0.8)\n",
    "train, test = df_final[:train_size], df_final[train_size:]\n",
    "\n",
    "# Define the range of values for p, d, and q\n",
    "p_values = range(0, 3)  # Adjust the range based on your data and context\n",
    "d_values = range(0, 2)\n",
    "q_values = range(0, 3)\n",
    "\n",
    "# Search through the parameter space\n",
    "best_score, best_order = float(\"inf\"), None\n",
    "\n",
    "for p in p_values:\n",
    "    for d in d_values:\n",
    "        for q in q_values:\n",
    "            order = (p, d, q)\n",
    "            try:\n",
    "                # Fit ARIMA model\n",
    "                arima_model = ARIMA(train, order=order)\n",
    "                arima_fit = arima_model.fit()\n",
    "\n",
    "                # Make predictions\n",
    "                arima_predictions = arima_fit.forecast(steps=len(test))\n",
    "\n",
    "                # Calculate RMSE\n",
    "                rmse = np.sqrt(mean_squared_error(test, arima_predictions))\n",
    "\n",
    "                # Update best parameters if needed\n",
    "                if rmse < best_score:\n",
    "                    best_score, best_order = rmse, order\n",
    "\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best ARIMA Order: {best_order}\")\n",
    "print(f\"Best RMSE: {best_score}\")\n",
    "\n",
    "# Fit the final model with the best parameters\n",
    "final_arima_model = ARIMA(df_final['Price'], order=best_order)\n",
    "final_arima_fit = final_arima_model.fit()\n",
    "\n",
    "# Make predictions for the entire dataset\n",
    "final_arima_predictions = final_arima_fit.forecast(steps=len(df_final))\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_final.index, df_final['Price'], label='Actual Prices')\n",
    "plt.plot(df_final.index, final_arima_predictions, label='ARIMA Predictions', linestyle='dashed')\n",
    "plt.title('Oil Price Prediction using ARIMA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "print(\"Mean Absolute Error:\", rf_mae)\n",
    "print(\"mean_squared_error\",rf_mse)\n",
    "print(\"root mean squared Error\",np.sqrt(rf_mse))\n",
    "\n",
    "#  AUto Regressor\n",
    "print(\"AR Model Evaluation:\")\n",
    "print(\"MAE:\", ar_mae)\n",
    "print(\"MSE:\", ar_mse)\n",
    "print(\"RMSE:\", ar_rmse)\n",
    "\n",
    "# Support Vector Classifier\n",
    "print(\"SVR Model Evaluation:\")\n",
    "print(\"MAE:\", svr_mae)\n",
    "print(\"MSE:\", svr_mse)\n",
    "print(\"RMSE:\", svr_rmse)\n",
    "\n",
    "# XGBRegressor\n",
    "print(\"XGBRegresso Model\")\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"mean_squared_error\",mse)\n",
    "print(\"Root Mean Squared Error\",np.sqrt(mse))\n",
    "\n",
    "# ARIMA model Without Hyperparameter\n",
    "print('ARIMA model Without Hyperparameter')\n",
    "print(arima_mae)\n",
    "print(arima_rmse)\n",
    "\n",
    "# ARIMA After Hyperparameter\n",
    "print(\"ARIMA model after Hyperparameter\")\n",
    "print(f\"Best RMSE: {best_score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Checking Above Value we Will Use Random Forest\n",
    "because Random Forest Gives least Error and ARIMA model as it is Time Series model gives less Error as compared to other time Sereis Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model Using Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Random Forestl\n",
    "\n",
    "#joblib.dump(model_rf, 'random_forest_model_save.pkl')\n",
    "\n",
    "# SAving ARIMA Model\n",
    "\n",
    "#joblib.dump(final_arima_fit,\"Arima_final_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
